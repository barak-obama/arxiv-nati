<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">

<!-- Mirrored from arxiv.org/list/eess/new by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 29 Mar 2019 22:40:36 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
<title>Electrical Engineering and Systems Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="../../favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="../../css/arXivfecf.css?v=20190306" />
<link rel="stylesheet" type="text/css" media="screen" href="../../bibex/bibex2785.css?20181009">
<link rel="stylesheet" href="../../../maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"> 
<link rel="alternate" type="application/rss+xml" title="Electrical Engineering and Systems Science " href="http://arxiv.org/rss/eess"/>
<script src="https://arxiv.org/js/mathjaxToggle.min.js" type="text/javascript"></script>

<!-- Piwik -->
<script type="text/javascript">
var _paq = _paq || [];
_paq.push(["setDomains", ["*.arxiv.org"]]);
_paq.push(['trackPageView']);
_paq.push(['enableLinkTracking']);
(function()
{ var u="../../../webanalytics.library.cornell.edu/index.html"; _paq.push(['setTrackerUrl', u+'piwik.php']); _paq.push(['setSiteId', 538]); var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0]; g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s); }
)();
</script>
<!-- End Piwik Code -->


</head>
<body class="with-cu-identity">

<noscript><img src="../../../webanalytics.library.cornell.edu/piwikf25d.gif?idsite=538&amp;rec=1" style="border:0;" alt="" /></noscript>

<div id="cu-identity">
<div id="cu-logo">
<a href="../../../www.cornell.edu/index.html"><img src="../../../static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1><a href="../../index.html">arXiv.org</a> &gt; <a href="recent.html">eess</a></h1>
<div id="search">
<form id="search-arxiv" method="GET" action="https://arxiv.org/search">
                
<div class="wrapper-search-arxiv">
<input class="keyword-field" type="text" name="query" placeholder="Search or Article ID"/>

<div class="filter-field">
<select name="searchtype">
<option value="all">All fields</option>
<option value="title">Title</option>
<option value="author">Author(s)</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option></select>
</div>
<input class="btn-search-arxiv" value="" type="submit">
<div class="links">(<a href="../../help.html">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced search</a>)</div>
</div>
<input type="hidden" name="source" value="header">
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Electrical Engineering and Systems Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed 27 Mar 19  to  Thu 28 Mar 19, announced Fri, 29 Mar 19</div>
<ul>
<li><a href="https://arxiv.org/list/eess/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item14">Cross-lists</a></li>
<li><a href="#item19">Replacements</a></li>
</ul>
<small>[ total of 25 entries:  <b>1-25</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="https://arxiv.org/list/eess/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri, 29 Mar 19</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11593" title="Abstract">arXiv:1903.11593</a> [<a href="https://arxiv.org/pdf/1903.11593" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What does AI see? Deep segmentation networks discover biomarkers for  lung cancer survival
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Baek%2C+S">Stephen Baek</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=He%2C+Y">Yusen He</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Allen%2C+B+G">Bryan G. Allen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Buatti%2C+J+M">John M. Buatti</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Smith%2C+B+J">Brian J. Smith</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Plichta%2C+K+A">Kristin A. Plichta</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Seyedin%2C+S+N">Steven N. Seyedin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gannon%2C+M">Maggie Gannon</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cabel%2C+K+R">Katherine R. Cabel</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kim%2C+Y">Yusung Kim</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wu%2C+X">Xiaodong Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Non-small-cell lung cancer (NSCLC) represents approximately 80-85% of lung
cancer diagnoses and is the leading cause of cancer-related death worldwide.
Recent studies indicate that image-based radiomics features from positron
emission tomography-computed tomography (PET/CT) images have predictive power
on NSCLC outcomes. To this end, easily calculated functional features such as
the maximum and the mean of standard uptake value (SUV) and total lesion
glycolysis (TLG) are most commonly used for NSCLC prognostication, but their
prognostic value remains controversial. Meanwhile, convolutional neural
networks (CNN) are rapidly emerging as a new premise for cancer image analysis,
with significantly enhanced predictive power compared to other hand-crafted
radiomics features. Here we show that CNN trained to perform the tumor
segmentation task, with no other information than physician contours, identify
a rich set of survival-related image features with remarkable prognostic value.
In a retrospective study on 96 NSCLC patients before stereotactic-body
radiotherapy (SBRT), we found that the CNN segmentation algorithm (U-Net)
trained for tumor segmentation in PET/CT images, contained features having
strong correlation with 2- and 5-year overall and disease-specific survivals.
The U-net algorithm has not seen any other clinical information (e.g. survival,
age, smoking history) than the images and the corresponding tumor contours
provided by physicians. Furthermore, through visualization of the U-Net, we
also found convincing evidence that the regions of progression appear to match
with the regions where the U-Net features identified patterns that predicted
higher likelihood of death. We anticipate our findings will be a starting point
for more sophisticated non-intrusive patient specific cancer prognosis
determination.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11703" title="Abstract">arXiv:1903.11703</a> [<a href="https://arxiv.org/pdf/1903.11703" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recurrent Neural Networks For Accurate RSSI Indoor Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hoang%2C+M+T">Minh Tu Hoang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yuen%2C+B">Brosnan Yuen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dong%2C+X">Xiaodai Dong</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lu%2C+T">Tao Lu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Westendorp%2C+R">Robert Westendorp</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Reddy%2C+K">Kishore Reddy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Received signal strength indicator (RSSI), WiFi indoor localization, recurrent neuron network (RNN), long shortterm memory (LSTM), fingerprint-based localization
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper proposes recurrent neuron networks (RNNs) for a fingerprinting
indoor localization using WiFi. Instead of locating user's position one at a
time as in the cases of conventional algorithms, our RNN solution aims at
trajectory positioning and takes into account the relation among the received
signal strength indicator (RSSI) measurements in a trajectory. Furthermore, a
weighted average filter is proposed for both input RSSI data and sequential
output locations to enhance the accuracy among the temporal fluctuations of
RSSI. The results using different types of RNN including vanilla RNN, long
short-term memory (LSTM), gated recurrent unit (GRU) and bidirectional LSTM
(BiLSTM) are presented. On-site experiments demonstrate that the proposed
structure achieves an average localization error of $0.75$ m with $80\%$ of the
errors under $1$ m, which outperforms the conventional KNN algorithms and
probabilistic algorithms by approximately $30\%$ under the same test
environment.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11726" title="Abstract">arXiv:1903.11726</a> [<a href="https://arxiv.org/pdf/1903.11726" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radiological images and machine learning: trends, perspectives, and  prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+Z">Zhenwei Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sejdic%2C+E">Ervin Sejdic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computers in Biology and Medicine (2019)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The application of machine learning to radiological images is an increasingly
active research area that is expected to grow in the next five to ten years.
Recent advances in machine learning have the potential to recognize and
classify complex patterns from different radiological imaging modalities such
as x-rays, computed tomography, magnetic resonance imaging and positron
emission tomography imaging. In many applications, machine learning based
systems have shown comparable performance to human decision-making. The
applications of machine learning are the key ingredients of future clinical
decision making and monitoring systems. This review covers the fundamental
concepts behind various machine learning techniques and their applications in
several radiological imaging areas, such as medical image segmentation, brain
function studies and neurological disease diagnosis, as well as computer-aided
systems, image registration, and content-based image retrieval systems.
Synchronistically, we will briefly discuss current challenges and future
directions regarding the application of machine learning in radiological
imaging. By giving insight on how take advantage of machine learning powered
applications, we expect that clinicians can prevent and diagnose diseases more
accurately and efficiently.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11827" title="Abstract">arXiv:1903.11827</a> [<a href="https://arxiv.org/pdf/1903.11827" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel approach to robust radar detection of range-spread targets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Coluccia%2C+A">Angelo Coluccia</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fascista%2C+A">Alessio Fascista</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ricci%2C+G">Giuseppe Ricci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>

</div>
<p class="mathjax">This paper proposes a novel approach to robust radar detection of
range-spread targets embedded in Gaussian noise with unknown covariance matrix.
The idea is to model the useful target echo in each range cell as the sum of a
coherent signal plus a random component that makes the signal-plus-noise
hypothesis more plausible in presence of mismatches. Moreover, an unknown power
of the random components, to be estimated from the observables, is inserted to
optimize the performance when the mismatch is absent. The generalized
likelihood ratio test (GLRT) for the problem at hand is considered. In
addition, a new parametric detector that encompasses the GLRT as a special case
is also introduced and assessed. The performance assessment shows the
effectiveness of the idea also in comparison to natural competitors.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11849" title="Abstract">arXiv:1903.11849</a> [<a href="https://arxiv.org/pdf/1903.11849" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inertial Sensor Aided mmWave Beam Tracking to Support Cooperative  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Brambilla%2C+M">Mattia Brambilla</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nicoli%2C+M">Monica Nicoli</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Savaresi%2C+S">Sergio Savaresi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Spagnolini%2C+U">Umberto Spagnolini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE ICC 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This paper presents an inertial sensor aided technique for beam alignment and
tracking in massive multiple-input multiple-output (MIMO) vehicle-to-vehicle
(V2V) communications based on millimeter waves (mmWave). Since directional
communications in vehicular scenarios are severely hindered by beam pointing
issues, a beam alignment procedure has to be periodically carried out to
guarantee the communication reliability. When dealing with massive MIMO links,
the beam sweeping approach is known to be time consuming and often unfeasible
due to latency constraints. To speed up the process, we propose a method that
exploits a-priori information on array dynamics provided by an inertial sensor
on transceivers to assist the beam alignment procedure. The proposed inertial
sensor aided technique allows a continuous tracking of the beam while
transmitting, avoiding frequent realignment phases. Numerical results based on
real measurements of on-transceiver accelerometers demonstrate a significant
gain in terms of V2V communication throughput with respect to conventional beam
alignment protocols.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11996" title="Abstract">arXiv:1903.11996</a> [<a href="https://arxiv.org/pdf/1903.11996" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To boldly go where no sensor has gone before: The movement to place IoT  in radical new spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Saeed%2C+N">Nasir Saeed</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Alouini%2C+M">Mohamed-Slim Alouini</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Al-Naffouri%2C+T+Y">Tareq Y. Al-Naffouri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE ComSoc News (CTN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In this article, we have presented an overview on a unified framework which
is called as the Internet of X-things (X-IoT) that will warrant the convergence
of emerging use cases of the Internet of Things everywhere around us, i.e.,
under the ground and oceans and even in the outer space. It is anticipated that
such a framework will foster the design and development of smart objects
capable of performing sensing under all-rounded environment and communication
technologies capable of offering ubiquitous connectivity of course with the
desired requirements. Through this framework, we get to know what has been done
since recently and how the technical challenges across the broad spectrum of
emerging use cases under the water, underground and over the space are
converging toward future solutions.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.12029" title="Abstract">arXiv:1903.12029</a> [<a href="https://arxiv.org/pdf/1903.12029" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sizing and Placement of Battery Energy Storage Systems and Wind Turbines  by Minimizing Costs and System Losses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Khaki%2C+B">Bahman Khaki</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Das%2C+P">Pritam Das</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 page , 8 figure, 7 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>

</div>
<p class="mathjax">Probabilistic and intermittent output power of wind turbines (WT) is one
major inconsistency of WTs. Battery Energy Storage Systems (BESSs) are a
suitable solution to mitigate this intermittency which use to smoothen the
output power injected to the grid by such intermittent sources. This paper
proposes a new optimization formulation using genetic algorithm to simultaneous
sizing and placement of BESSs and WTs which result in finding best location and
size (capacity) of WTs and BESSs in power system by minimizing total system
loss (active and reactive loss) and Costs of WTs and BESSs which improves
demand bus voltage profiles. The result of optimization problem is best buses
to locate WTs and BESSs and the size (installable active and reactive power) of
them. The case studies performed on IEEE 33 bus system, validates the
suitability of the formulation for loss minimization and bus voltage profiles
improvement in the test system in presence of WT and BESS.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.12053" title="Abstract">arXiv:1903.12053</a> [<a href="https://arxiv.org/pdf/1903.12053" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imaging cytometry without image reconstruction (ghost cytometry)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ota%2C+S">Sadao Ota</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Horisaki%2C+R">Ryoichi Horisaki</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kawamura%2C+Y">Yoko Kawamura</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sato%2C+I">Issei Sato</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Noji%2C+H">Hiroyuki Noji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>

</div>
<p class="mathjax">Imaging and analysis of many single cells hold great potential in our
understanding of heterogeneous and complex life systems and in enabling
biomedical applications. We here introduce a recently realized image-free
"imaging" cytometry technology, which we call ghost cytometry. While a
compressive ghost imaging technique utilizing object's motion relative to a
projected static light pattern allows recovery of their images, a key of this
ghost cytometry is to achieve ultrafast cell classification by directly
applying machine learning methods to the compressive imaging signals in a
temporal domain. We show the applicability of our method in the analysis of
flowing objects based on the reconstructed images as well as in that based on
the imaging waveform without image production.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.12058" title="Abstract">arXiv:1903.12058</a> [<a href="https://arxiv.org/pdf/1903.12058" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.12058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Network Embedding Learning with High-Order Statistics for  Text-Independent Speaker Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=You%2C+L">Lanhua You</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guo%2C+W">Wu Guo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dai%2C+L">Lirong Dai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Du%2C+J">Jun Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,2 figures, submitted to INTERSPEECH 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The x-vector based deep neural network (DNN) embedding systems have
demonstrated effectiveness for text-independent speaker verification. This
paper presents a multi-task learning architecture for training the speaker
embedding DNN, with the primary task of classifying the target speakers and the
auxiliary task of reconstructing the higher-order statistics of the original
input utterance. The proposed training strategy aggregates both the supervised
and unsupervised learning into one framework to make the speaker embeddings
more discriminative and robust. Experiments are carried out in the NIST SRE16
evaluation dataset and the VOiCES dataset. The results demonstrate that our
proposed method outperform the original x-vector approach with very low
additional complexity added.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.12087" title="Abstract">arXiv:1903.12087</a> [<a href="https://arxiv.org/pdf/1903.12087" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.12087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Real-Time Wideband Neural Vocoder at 1.6 kb/s Using LPCNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Valin%2C+J">Jean-Marc Valin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Skoglund%2C+J">Jan Skoglund</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for Interspeech 2019, 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Neural speech synthesis algorithms are a promising new approach for coding
speech at very low bitrate. They have so far demonstrated quality that far
exceeds traditional vocoders, at the cost of very high complexity. In this
work, we present a low-bitrate neural vocoder based on the LPCNet model. The
use of linear prediction and sparse recurrent networks makes it possible to
achieve real-time operation on general-purpose hardware. We demonstrate that
LPCNet operating at 1.6 kb/s achieves significantly higher quality than MELP
and that uncompressed LPCNet can exceed the quality of a waveform codec
operating at low bitrate. This opens the way for new codec designs based on
neural synthesis models.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.12089" title="Abstract">arXiv:1903.12089</a> [<a href="https://arxiv.org/pdf/1903.12089" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.12089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Unmixing: A Derivation of the Extended Linear Mixing Model from  the Hapke Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Drumetz%2C+L">Lucas Drumetz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chanussot%2C+J">Jocelyn Chanussot</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jutten%2C+C">Christian Jutten</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>

</div>
<p class="mathjax">In hyperspectral imaging, spectral unmixing aims at decomposing the image
into a set of reference spectral signatures corresponding to the materials
present in the observed scene and their relative proportions in every pixel.
While a linear mixing model was used for a long time, the complex nature of the
physical mixing processes, led to shift the community's attention towards
nonlinear models and algorithms accounting for the variability of the
endmembers. Such intra class variations are due to local changes in the
physico-chemical composition of the materials, and to illumination changes. In
the physical remote sensing community, a popular model accounting for
illumination variability is the radiative transfer model proposed by Hapke. It
is however too complex to be directly used in hyperspectral unmixing in a
tractable way. Instead, the Extended Linear Mixing Model (ELMM) allows to
easily unmix hyperspectral data accounting for changing illumination
conditions. In this letter, we show that the ELMM can be obtained from the
Hapke model by successive simplifiying physical assumptions, thus theoretically
confirming its relevance to handle illumination induced variability in the
unmixing problem.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.12092" title="Abstract">arXiv:1903.12092</a> [<a href="https://arxiv.org/pdf/1903.12092" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.12092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Network Embeddings with Gating Mechanisms for  Text-Independent Speaker Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=You%2C+L">Lanhua You</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guo%2C+W">Wu Guo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dai%2C+L">Lirong Dai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Du%2C+J">Jun Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, submitted to INTERSPEECH 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">In this paper, gating mechanisms are applied in deep neural network (DNN)
training for x-vector-based text-independent speaker verification. First, a
gated convolution neural network (GCNN) is employed for modeling the
frame-level embedding layers. Compared with the time-delay DNN (TDNN), the GCNN
can obtain more expressive frame-level representations through carefully
designed memory cell and gating mechanisms. Moreover, we propose a novel
gated-attention statistics pooling strategy in which the attention scores are
shared with the output gate. The gated-attention statistics pooling combines
both gating and attention mechanisms into one framework; therefore, we can
capture more useful information in the temporal pooling layer. Experiments are
carried out using the NIST SRE16 and SRE18 evaluation datasets. The results
demonstrate the effectiveness of the GCNN and show that the proposed
gated-attention statistics pooling can further improve the performance.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.12149" title="Abstract">arXiv:1903.12149</a> [<a href="https://arxiv.org/pdf/1903.12149" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance and Energy Conservation of 3GPP IFOM Protocol for Dual  Connectivity in Heterogeneous LTE-WLAN Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gadgil%2C+S">Shubhada Gadgil</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ranjan%2C+S">Shashi Ranjan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Karandikar%2C+A">Abhay Karandikar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 15 figures, journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>

</div>
<p class="mathjax">For the 5th Generation (5G) networks, Third Generation Partnership Project
(3GPP) is considering standardization of various solutions for traffic
aggregation using licensed and unlicensed spectrum, to meet the rising data
demands. IP Flow Mobility (IFOM) is a multi access connectivity
solution/protocol standardized by the Internet Engineering Task force (IETF)
and 3GPP in Release 10. It enables concurrent access for an User Equipment (UE)
to Heterogeneous Networks (HetNets) such as Long Term Evolution (LTE) and IEEE
802.11 Wireless Local Area Network (WLAN). IFOM enabled UEs have multiple
interfaces to connect to HetNets. They can have concurrent flows with different
traffic types over these networks and can seamlessly switch the flows from one
network to the other. In this paper, we focus on two objectives. First is to
investigate the performance parameters e.g. throughput, latency, tunnelling
overhead, packet loss, energy cost etc. of IFOM enabled UEs (IeUs) in HetNets
of LTE and WLAN. We have proposed a novel mechanism to maximize the throughput
of IeUs achieving a significant throughput gain with low latency for the IeUs.
We have explored further and observed a throughput energy trade off for low
data rate flows. To address this, we also propose a smart energy efficient and
throughput optimization algorithm for the IeUs, resulting in a substantial
reduction in energy cost, while maintaining the high throughput at lower
latency and satisfying the Quality of Service (QoS) requirements of the IeUs.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri, 29 Mar 19</h3>
<dl>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11672" title="Abstract">arXiv:1903.11672</a> (cross-list from cs.SD) [<a href="https://arxiv.org/pdf/1903.11672" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuSE-ing on the Impact of Utterance Ordering On Crowdsourced Emotion  Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaiswal%2C+M">Mimansa Jaiswal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aldeneh%2C+Z">Zakaria Aldeneh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bara%2C+C">Cristian-Paul Bara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yuanhang Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burzo%2C+M">Mihai Burzo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mihalcea%2C+R">Rada Mihalcea</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Provost%2C+E+M">Emily Mower Provost</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, ICASSP 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Emotion recognition algorithms rely on data annotated with high quality
labels. However, emotion expression and perception are inherently subjective.
There is generally not a single annotation that can be unambiguously declared
"correct". As a result, annotations are colored by the manner in which they
were collected. In this paper, we conduct crowdsourcing experiments to
investigate this impact on both the annotations themselves and on the
performance of these algorithms. We focus on one critical question: the effect
of context. We present a new emotion dataset, Multimodal Stressed Emotion
(MuSE), and annotate the dataset using two conditions: randomized, in which
annotators are presented with clips in random order, and contextualized, in
which annotators are presented with clips in order. We find that contextual
labeling schemes result in annotations that are more similar to a speaker's own
self-reported labels and that labels generated from randomized schemes are most
easily predictable by automated systems.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11673" title="Abstract">arXiv:1903.11673</a> (cross-list from cs.LG) [<a href="https://arxiv.org/pdf/1903.11673" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Deep Learning in EEG Biometrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ozdenizci%2C+O">Ozan Ozdenizci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Ye Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koike-Akino%2C+T">Toshiaki Koike-Akino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Erdogmus%2C+D">Deniz Erdogmus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication by IEEE Signal Processing Letters
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Signal Processing Letters, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep learning methods for person identification based on
electroencephalographic (EEG) brain activity encounters the problem of
exploiting the temporally correlated structures or recording session specific
variability within EEG. Furthermore, recent methods have mostly trained and
evaluated based on single session EEG data. We address this problem from an
invariant representation learning perspective. We propose an adversarial
inference approach to extend such deep learning models to learn
session-invariant person-discriminative representations that can provide
robustness in terms of longitudinal usability. Using adversarial learning
within a deep convolutional network, we empirically assess and show
improvements with our approach based on longitudinally collected EEG data for
person identification from half-second EEG epochs.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11696" title="Abstract">arXiv:1903.11696</a> (cross-list from stat.ML) [<a href="https://arxiv.org/pdf/1903.11696" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable prediction with radiomics data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Peeters%2C+C+F+W">Carel F.W. Peeters</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=%C3%9Cbelh%C3%B6r%2C+C">Caroline &#xdc;belh&#xf6;r</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Mes%2C+S+W">Steven W. Mes</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Martens%2C+R">Roland Martens</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Koopman%2C+T">Thomas Koopman</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=de+Graaf%2C+P">Pim de Graaf</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=van+Velden%2C+F+H+P">Floris H.P. van Velden</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Boellaard%2C+R">Ronald Boellaard</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Castelijns%2C+J+A">Jonas A. Castelijns</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Beest%2C+D+E+t">Dennis E. te Beest</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Heymans%2C+M+W">Martijn W. Heymans</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=van+de+Wiel%2C+M+A">Mark A. van de Wiel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages: 14 pages Main Text and 38 pages of Supplementary Material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Quantitative Methods (q-bio.QM); Applications (stat.AP); Methodology (stat.ME)

</div>
<p class="mathjax">Motivation: Radiomics refers to the high-throughput mining of quantitative
features from radiographic images. It is a promising field in that it may
provide a non-invasive solution for screening and classification. Standard
machine learning classification and feature selection techniques, however, tend
to display inferior performance in terms of (the stability of) predictive
performance. This is due to the heavy multicollinearity present in radiomic
data. We set out to provide an easy-to-use approach that deals with this
problem.
<br />Results: We developed a four-step approach that projects the original
high-dimensional feature space onto a lower-dimensional latent-feature space,
while retaining most of the covariation in the data. It consists of (i)
penalized maximum likelihood estimation of a redundancy filtered correlation
matrix. The resulting matrix (ii) is the input for a maximum likelihood factor
analysis procedure. This two-stage maximum-likelihood approach can be used to
(iii) produce a compact set of stable features that (iv) can be directly used
in any (regression-based) classifier or predictor. It outperforms other
classification (and feature selection) techniques in both external and internal
validation settings regarding survival in squamous cell cancers.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11791" title="Abstract">arXiv:1903.11791</a> (cross-list from cs.SD) [<a href="https://arxiv.org/pdf/1903.11791" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Pooling Structure for Weakly Labeled Sound Event Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+K">Ke-Xin He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yu-Han Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wei-Qiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Sound event detection with weakly labeled data is considered as a problem of
multi-instance learning. And the choice of pooling function is the key to
solving this problem. In this paper, we proposed a hierarchical pooling
structure to improve the performance of weakly labeled sound event detection
system. Proposed pooling structure has made remarkable improvements on three
types of pooling function without adding any parameters. Moreover, our system
has achieved competitive performance on Task 4 of Detection and Classification
of Acoustic Scenes and Events (DCASE) 2017 Challenge using hierarchical pooling
structure.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.12094" title="Abstract">arXiv:1903.12094</a> (cross-list from cs.LG) [<a href="https://arxiv.org/pdf/1903.12094" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Barking up the Right Tree: Improving Cross-Corpus Speech Emotion  Recognition with Adversarial Discriminative Domain Generalization (ADDoG)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gideon%2C+J">John Gideon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McInnis%2C+M+G">Melvin G McInnis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Provost%2C+E+M">Emily Mower Provost</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS); Machine Learning (stat.ML)

</div>
<p class="mathjax">Automatic speech emotion recognition provides computers with critical context
to enable user understanding. While methods trained and tested within the same
dataset have been shown successful, they often fail when applied to unseen
datasets. To address this, recent work has focused on adversarial methods to
find more generalized representations of emotional speech. However, many of
these methods have issues converging, and only involve datasets collected in
laboratory conditions. In this paper, we introduce Adversarial Discriminative
Domain Generalization (ADDoG), which follows an easier to train "meet in the
middle" approach. The model iteratively moves representations learned for each
dataset closer to one another, improving cross-dataset generalization. We also
introduce Multiclass ADDoG, or MADDoG, which is able to extend the proposed
method to more than two datasets, simultaneously. Our results show consistent
convergence for the introduced methods, with significantly improved results
when not using labels from the target dataset. We also show how, in most cases,
ADDoG and MADDoG can be used to improve upon baseline state-of-the-art methods
when target dataset labels are added and in-the-wild data are considered. Even
though our experiments focus on cross-corpus speech emotion, these methods
could be used to remove unwanted factors of variation in other settings.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri, 29 Mar 19</h3>
<dl>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1802.04634" title="Abstract">arXiv:1802.04634</a> (replaced) [<a href="https://arxiv.org/pdf/1802.04634" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1802.04634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lattice Functions for the Analysis of Analog-to-Digital Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mart%C3%ADnez-Nuevo%2C+P">Pablo Mart&#xed;nez-Nuevo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Oppenheim%2C+A+V">Alan. V. Oppenheim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Complex Variables (math.CV)

</div>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1802.04672" title="Abstract">arXiv:1802.04672</a> (replaced) [<a href="https://arxiv.org/pdf/1802.04672" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1802.04672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delta-Ramp Encoder for Amplitude Sampling and its Interpretation as Time  Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mart%C4%B1nez-Nuevo%2C+P">Pablo Mart&#x131;nez-Nuevo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Oppenheim%2C+A+V">Alan V. Oppenheim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures, journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Complex Variables (math.CV)

</div>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1805.10232" title="Abstract">arXiv:1805.10232</a> (replaced) [<a href="https://arxiv.org/pdf/1805.10232" title="Download PDF">pdf</a>, <a href="https://arxiv.org/ps/1805.10232" title="Download PostScript">ps</a>, <a href="https://arxiv.org/format/1805.10232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperspectral Image Unmixing with Endmember Bundles and Group Sparsity  Inducing Mixed Norms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Drumetz%2C+L">Lucas Drumetz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Meyer%2C+T+R">Travis R. Meyer</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chanussot%2C+J">Jocelyn Chanussot</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bertozzi%2C+A+L">Andrea L. Bertozzi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jutten%2C+C">Christian Jutten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in IEEE Transactions on Image Processing,2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>

</div>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1809.08514" title="Abstract">arXiv:1809.08514</a> (replaced) [<a href="https://arxiv.org/pdf/1809.08514" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1809.08514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fundamental Limits of Invisible Flow Fingerprinting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soltani%2C+R">Ramin Soltani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goeckel%2C+D">Dennis Goeckel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Towsley%2C+D">Don Towsley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Houmansadr%2C+A">Amir Houmansadr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.09394" title="Abstract">arXiv:1903.09394</a> (replaced) [<a href="https://arxiv.org/pdf/1903.09394" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.09394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Predistortion for Multiuser Hybrid MIMO at mmWaves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Brihuega%2C+A">Alberto Brihuega</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Anttila%2C+L">Lauri Anttila</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Abdelaziz%2C+M">Mahmoud Abdelaziz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tufvesson%2C+F">Fredrik Tufvesson</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Valkama%2C+M">Mikko Valkama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, updated Journal; submitted to IEEE Transactions on Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>

</div>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.09836" title="Abstract">arXiv:1903.09836</a> (replaced) [<a href="https://arxiv.org/pdf/1903.09836" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.09836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal phase unwrapping using deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yin%2C+W">Wei Yin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+Q">Qian Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Feng%2C+S">Shijie Feng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tao%2C+T">Tianyang Tao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+L">Lei Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Trusiak%2C+M">Maciej Trusiak</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Asundi%2C+A">Anand Asundi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zuo%2C+C">Chao Zuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>

</div>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11210" title="Abstract">arXiv:1903.11210</a> (replaced) [<a href="https://arxiv.org/pdf/1903.11210" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Colorectal cancer diagnosis from histology images: A comparative study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malik%2C+J">Junaid Malik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kiranyaz%2C+S">Serkan Kiranyaz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kunhoth%2C+S">Suchitra Kunhoth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ince%2C+T">Turker Ince</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Al-Maadeed%2C+S">Somaya Al-Maadeed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hamila%2C+R">Ridha Hamila</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gabbouj%2C+M">Moncef Gabbouj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="https://arxiv.org/list/eess/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item14">Cross-lists</a></li>
<li><a href="#item19">Replacements</a></li>
</ul>
<small>[ total of 25 entries:  <b>1-25</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="https://arxiv.org/list/eess/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="https://arxiv.org/help/mathjax/">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="../../index.html" accesskey="a">arXiv</a>, 
<a href="https://arxiv.org/form/eess">form interface</a>,
<a href="https://arxiv.org/find/eess">find</a>,
<a href="../../archive/eess.html">eess</a>, <a href="recent.html">recent</a>, <a href="https://arxiv.org/list/eess/1903">1903</a>,
<a href="../../help/contact.html">contact</a>,
<a href="https://arxiv.org/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="https://arxiv.org/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
  <footer style="clear: both;">
    <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
      <!-- Macro-Column 1 -->
      <div class="column" style="padding: 0;">
        <div class="columns">
          <div class="column">
            <ul style="list-style: none; line-height: 2;">
              <li><a href="../../about.html">About arXiv</a></li>
              <li><a href="../../about/people/leadership_team.html">Leadership Team</a></li>
            </ul>
          </div>
          <div class="column">
            <ul style="list-style: none; line-height: 2;">
              <li><span class="icon"><i class="fa fa-envelope"></i></span><a href="../../help/contact.html"> Contact Us</a></li>
              <li><span class="icon"><i class="fa fa-twitter"></i></span><a href="../../../twitter.com/arxiv.html"> Follow us on Twitter</a></li>
            </ul>
          </div>
        </div>
      </div>
      <!-- End Macro-Column 1 -->
      <!-- Macro-Column 2 -->
      <div class="column" style="padding: 0;">
        <div class="columns">
          <div class="column">
            <ul style="list-style: none; line-height: 2;">
              <li><a href="../../help.html">Help</a></li>
              <li><a href="../../help/policies/privacy_policy.html">Privacy Policy</a></li>
            </ul>
          </div>
          <div class="column">
            <ul style="list-style: none; line-height: 2;">
              <li><a href="https://blogs.cornell.edu/arxiv">Blog</a></li>
              <li><a href="../../help/subscribe.html"> Subscribe</a></li>
            </ul>
          </div>
        </div>
      </div>
      <!-- End Macro-Column 2 -->
    </div>

    <div class="columns" style="border-top: 1px solid #979797; margin: -0.75em;">
      <div class="column">
        <p class="help" style="margin-bottom: 0;">arXiv&#174; is a registered trademark of Cornell University.</p>
      </div>
      <div class="column">
        <p class="help" style="margin-bottom: 0;">If you have a disability and are having trouble accessing information on this website or need materials in an alternate format,
        contact <a href="mailto:web-accessibility@cornell.edu">web-accessibility@cornell.edu</a> for assistance.</p>
      </div>
    </div>
  </footer>
</body>

<!-- Mirrored from arxiv.org/list/eess/new by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 29 Mar 2019 22:40:36 GMT -->
</html>
