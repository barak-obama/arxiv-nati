<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">

<!-- Mirrored from arxiv.org/list/cs.SD/recent by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 29 Mar 2019 22:40:35 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
<title>Sound  authors/titles recent submissions</title>
<link rel="shortcut icon" href="../../favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="../../css/arXivfecf.css?v=20190306" />
<link rel="stylesheet" type="text/css" media="screen" href="../../bibex/bibex2785.css?20181009">
<link rel="stylesheet" href="../../../maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"> 
<link rel="alternate" type="application/rss+xml" title="Sound " href="http://arxiv.org/rss/cs.SD"/>
<script src="https://arxiv.org/js/mathjaxToggle.min.js" type="text/javascript"></script>

<!-- Piwik -->
<script type="text/javascript">
var _paq = _paq || [];
_paq.push(["setDomains", ["*.arxiv.org"]]);
_paq.push(['trackPageView']);
_paq.push(['enableLinkTracking']);
(function()
{ var u="../../../webanalytics.library.cornell.edu/index.html"; _paq.push(['setTrackerUrl', u+'piwik.php']); _paq.push(['setSiteId', 538]); var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0]; g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s); }
)();
</script>
<!-- End Piwik Code -->


</head>
<body class="with-cu-identity">

<noscript><img src="../../../webanalytics.library.cornell.edu/piwikf25d.gif?idsite=538&amp;rec=1" style="border:0;" alt="" /></noscript>

<div id="cu-identity">
<div id="cu-logo">
<a href="../../../www.cornell.edu/index.html"><img src="../../../static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1><a href="../../index.html">arXiv.org</a> &gt; <a href="../cs/recent.html">cs</a> &gt; <a href="recent.html">cs.SD</a></h1>
<div id="search">
<form id="search-arxiv" method="GET" action="https://arxiv.org/search">
                
<div class="wrapper-search-arxiv">
<input class="keyword-field" type="text" name="query" placeholder="Search or Article ID"/>

<div class="filter-field">
<select name="searchtype">
<option value="all">All fields</option>
<option value="title">Title</option>
<option value="author">Author(s)</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option></select>
</div>
<input class="btn-search-arxiv" value="" type="submit">
<div class="links">(<a href="../../help.html">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced search</a>)</div>
</div>
<input type="hidden" name="source" value="header">
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Sound </h1>
<h2>Authors and titles for recent submissions</h2>
<ul>
<li><a href="https://arxiv.org/list/cs.SD/pastweek?skip=0&amp;show=25">Fri, 29 Mar 2019</a></li>
<li><a href="#item7">Thu, 28 Mar 2019</a></li>
<li><a href="#item9">Wed, 27 Mar 2019</a></li>
<li><a href="#item14">Tue, 26 Mar 2019</a></li>
<li><a href="#item17">Mon, 25 Mar 2019</a></li>
</ul>
<small>[ total of 18 entries:  <b>1-18</b>  ]</small><br />
<small>[ showing up to 25 entries per page:  <a href="https://arxiv.org/list/cs.SD/pastweek?skip=0&amp;show=10">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>Fri, 29 Mar 2019</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11791" title="Abstract">arXiv:1903.11791</a> [<a href="https://arxiv.org/pdf/1903.11791" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Pooling Structure for Weakly Labeled Sound Event Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+K">Ke-Xin He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yu-Han Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wei-Qiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11672" title="Abstract">arXiv:1903.11672</a> [<a href="https://arxiv.org/pdf/1903.11672" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuSE-ing on the Impact of Utterance Ordering On Crowdsourced Emotion  Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaiswal%2C+M">Mimansa Jaiswal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aldeneh%2C+Z">Zakaria Aldeneh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bara%2C+C">Cristian-Paul Bara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yuanhang Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burzo%2C+M">Mihai Burzo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mihalcea%2C+R">Rada Mihalcea</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Provost%2C+E+M">Emily Mower Provost</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, ICASSP 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.12094" title="Abstract">arXiv:1903.12094</a> (cross-list from cs.LG) [<a href="https://arxiv.org/pdf/1903.12094" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Barking up the Right Tree: Improving Cross-Corpus Speech Emotion  Recognition with Adversarial Discriminative Domain Generalization (ADDoG)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gideon%2C+J">John Gideon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McInnis%2C+M+G">Melvin G McInnis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Provost%2C+E+M">Emily Mower Provost</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.12092" title="Abstract">arXiv:1903.12092</a> (cross-list from eess.AS) [<a href="https://arxiv.org/pdf/1903.12092" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.12092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Network Embeddings with Gating Mechanisms for  Text-Independent Speaker Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=You%2C+L">Lanhua You</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guo%2C+W">Wu Guo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dai%2C+L">Lirong Dai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Du%2C+J">Jun Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, submitted to INTERSPEECH 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.12087" title="Abstract">arXiv:1903.12087</a> (cross-list from eess.AS) [<a href="https://arxiv.org/pdf/1903.12087" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.12087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Real-Time Wideband Neural Vocoder at 1.6 kb/s Using LPCNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Valin%2C+J">Jean-Marc Valin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Skoglund%2C+J">Jan Skoglund</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for Interspeech 2019, 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.12058" title="Abstract">arXiv:1903.12058</a> (cross-list from eess.AS) [<a href="https://arxiv.org/pdf/1903.12058" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.12058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Network Embedding Learning with High-Order Statistics for  Text-Independent Speaker Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=You%2C+L">Lanhua You</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guo%2C+W">Wu Guo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dai%2C+L">Lirong Dai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Du%2C+J">Jun Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,2 figures, submitted to INTERSPEECH 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
</dl>
<h3>Thu, 28 Mar 2019</h3>
<dl>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11570" title="Abstract">arXiv:1903.11570</a> (cross-list from cs.CL) [<a href="https://arxiv.org/pdf/1903.11570" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualization and Interpretation of Latent Spaces for Controlling  Expressive Speech Synthesis through Audio Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tits%2C+N">No&#xe9; Tits</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+F">Fengna Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haddad%2C+K+E">Kevin El Haddad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pagel%2C+V">Vincent Pagel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dutoit%2C+T">Thierry Dutoit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.11399" title="Abstract">arXiv:1903.11399</a> (cross-list from eess.SP) [<a href="https://arxiv.org/pdf/1903.11399" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.11399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmented Ultrasonic Data for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Virkkunen%2C+I">Iikka Virkkunen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Koskinen%2C+T">Tuomas Koskinen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jessen-Juhler%2C+O">Oskari Jessen-Juhler</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rinta-Aho%2C+J">Jari Rinta-Aho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
</dl>
<h3>Wed, 27 Mar 2019</h3>
<dl>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.10839" title="Abstract">arXiv:1903.10839</a> [<a href="https://arxiv.org/pdf/1903.10839" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.10839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Musical Tempo and Key Estimation using Convolutional Neural Networks  with Directional Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schreiber%2C+H">Hendrik Schreiber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%BCller%2C+M">Meinard M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Sound &amp; Music Computing Conference (SMC), M\'alaga, Spain, May 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.10729" title="Abstract">arXiv:1903.10729</a> [<a href="https://arxiv.org/pdf/1903.10729" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.10729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WGANSing: A Multi-Voice Singing Voice Synthesizer Based on the  Wasserstein-GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chandna%2C+P">Pritish Chandna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blaauw%2C+M">Merlijn Blaauw</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bonada%2C+J">Jordi Bonada</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gomez%2C+E">Emilia Gomez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at EUSIPCO 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.10703" title="Abstract">arXiv:1903.10703</a> [<a href="https://arxiv.org/pdf/1903.10703" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditioning a Recurrent Neural Network to synthesize musical instrument  transients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wyse%2C+L">Lonce Wyse</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huzaifah%2C+M">Muhammad Huzaifah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Sound and Music Computing Conference. Malaga, Spain, May 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.10713" title="Abstract">arXiv:1903.10713</a> (cross-list from eess.AS) [<a href="https://arxiv.org/pdf/1903.10713" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.10713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale CNN based Deep Metric Learning for Bioacoustic  Classification: Overcoming Training Data Scarcity Using Dynamic Triplet Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Thakur%2C+A">Anshul Thakur</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Thapar%2C+D">Daksh Thapar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rajan%2C+P">Padmanabhan Rajan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nigam%2C+A">Aditya Nigam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review at JASA. Primitive version of paper. We are still working on getting better performances out of the comparative methods
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.10534" title="Abstract">arXiv:1903.10534</a> (cross-list from cs.CV) [<a href="https://arxiv.org/pdf/1903.10534" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.10534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Embodied Semantics via Music and Dance Semiotic Correlations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raposo%2C+F+A">Francisco Afonso Raposo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Matos%2C+D+M">David Martins de Matos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ribeiro%2C+R">Ricardo Ribeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 1 figure, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
</dl>
<h3>Tue, 26 Mar 2019</h3>
<dl>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.09803" title="Abstract">arXiv:1903.09803</a> [<a href="https://arxiv.org/pdf/1903.09803" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotion Recognition based on Third-Order Circular Suprasegmental Hidden  Markov Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahin%2C+I">Ismail Shahin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The 2019 IEEE Jordan International Joint Conference on Electrical Engineering and Information Technology (JEEIT), Jordan
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.10346" title="Abstract">arXiv:1903.10346</a> (cross-list from eess.AS) [<a href="https://arxiv.org/pdf/1903.10346" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.10346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imperceptible, Robust, and Targeted Adversarial Examples for Automatic  Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Qin%2C+Y">Yao Qin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Carlini%2C+N">Nicholas Carlini</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Goodfellow%2C+I">Ian Goodfellow</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cottrell%2C+G">Garrison Cottrell</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Raffel%2C+C">Colin Raffel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.09952" title="Abstract">arXiv:1903.09952</a> (cross-list from eess.AS) [<a href="https://arxiv.org/pdf/1903.09952" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.09952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization of Speaker Extraction Neural Network with Magnitude and  Temporal Spectrum Approximation Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xu%2C+C">Chenglin Xu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rao%2C+W">Wei Rao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chng%2C+E+S">Eng Siong Chng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICASSP 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
</dl>
<h3>Mon, 25 Mar 2019</h3>
<dl>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.09341" title="Abstract">arXiv:1903.09341</a> [<a href="https://arxiv.org/pdf/1903.09341" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.09341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Speech Enhancement Based on Multichannel NMF-Informed  Beamforming for Noise-Robust Automatic Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shimada%2C+K">Kazuki Shimada</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mimura%2C+M">Masato Mimura</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Itoyama%2C+K">Katsutoshi Itoyama</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoshii%2C+K">Kazuyoshi Yoshii</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawahara%2C+T">Tatsuya Kawahara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="https://arxiv.org/abs/1903.09606" title="Abstract">arXiv:1903.09606</a> (cross-list from eess.AS) [<a href="https://arxiv.org/pdf/1903.09606" title="Download PDF">pdf</a>, <a href="https://arxiv.org/format/1903.09606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards adversarial learning of speaker-invariant representation for  speech emotion recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tu%2C+M">Ming Tu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tang%2C+Y">Yun Tang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+J">Jing Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=He%2C+X">Xiaodong He</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhou%2C+B">Bowen Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="https://arxiv.org/list/cs.SD/pastweek?skip=0&amp;show=25">Fri, 29 Mar 2019</a></li>
<li><a href="#item7">Thu, 28 Mar 2019</a></li>
<li><a href="#item9">Wed, 27 Mar 2019</a></li>
<li><a href="#item14">Tue, 26 Mar 2019</a></li>
<li><a href="#item17">Mon, 25 Mar 2019</a></li>
</ul>
<small>[ total of 18 entries:  <b>1-18</b>  ]</small><br />
<small>[ showing up to 25 entries per page:  <a href="https://arxiv.org/list/cs.SD/pastweek?skip=0&amp;show=10">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="https://arxiv.org/help/mathjax/">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="../../index.html" accesskey="a">arXiv</a>, 
<a href="https://arxiv.org/form/cs">form interface</a>,
<a href="https://arxiv.org/find/cs">find</a>,
<a href="https://arxiv.org/archive/cs">cs</a>, <a href="../cs/new.html">new</a>, <a href="https://arxiv.org/list/cs/1903">1903</a>,
<a href="../../help/contact.html">contact</a>,
<a href="https://arxiv.org/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="https://arxiv.org/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
  <footer style="clear: both;">
    <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
      <!-- Macro-Column 1 -->
      <div class="column" style="padding: 0;">
        <div class="columns">
          <div class="column">
            <ul style="list-style: none; line-height: 2;">
              <li><a href="../../about.html">About arXiv</a></li>
              <li><a href="../../about/people/leadership_team.html">Leadership Team</a></li>
            </ul>
          </div>
          <div class="column">
            <ul style="list-style: none; line-height: 2;">
              <li><span class="icon"><i class="fa fa-envelope"></i></span><a href="../../help/contact.html"> Contact Us</a></li>
              <li><span class="icon"><i class="fa fa-twitter"></i></span><a href="../../../twitter.com/arxiv.html"> Follow us on Twitter</a></li>
            </ul>
          </div>
        </div>
      </div>
      <!-- End Macro-Column 1 -->
      <!-- Macro-Column 2 -->
      <div class="column" style="padding: 0;">
        <div class="columns">
          <div class="column">
            <ul style="list-style: none; line-height: 2;">
              <li><a href="../../help.html">Help</a></li>
              <li><a href="../../help/policies/privacy_policy.html">Privacy Policy</a></li>
            </ul>
          </div>
          <div class="column">
            <ul style="list-style: none; line-height: 2;">
              <li><a href="https://blogs.cornell.edu/arxiv">Blog</a></li>
              <li><a href="../../help/subscribe.html"> Subscribe</a></li>
            </ul>
          </div>
        </div>
      </div>
      <!-- End Macro-Column 2 -->
    </div>

    <div class="columns" style="border-top: 1px solid #979797; margin: -0.75em;">
      <div class="column">
        <p class="help" style="margin-bottom: 0;">arXiv&#174; is a registered trademark of Cornell University.</p>
      </div>
      <div class="column">
        <p class="help" style="margin-bottom: 0;">If you have a disability and are having trouble accessing information on this website or need materials in an alternate format,
        contact <a href="mailto:web-accessibility@cornell.edu">web-accessibility@cornell.edu</a> for assistance.</p>
      </div>
    </div>
  </footer>
</body>

<!-- Mirrored from arxiv.org/list/cs.SD/recent by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 29 Mar 2019 22:40:35 GMT -->
</html>
